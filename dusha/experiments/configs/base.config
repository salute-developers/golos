from .data import *

from core.dataset import MelEmotionsDataset, get_augm_func, adaptive_padding_collate_fn, LengthWeightedSampler
from core.model import ConvSelfAttentionMobileNet
from core.utils import load_jsonl_as_df
from torch.utils.data import DataLoader
from pathlib import Path

# train data
train_manifest_path = base_path / 'train' / 'crowd_train.jsonl'
val_manifest_path = base_path / 'tests' / 'crowd_test.jsonl'

# pretrain
pt_model_path = None

# exp hyperparams
batch_size = 64
epoch_count = 100
learning_rate = 5e-4
optimizer_step = 5
optimizer_gamma = 1
weight_decay = 1e-6
clip_grad = False

# augm and batch iter stuff
collate_fn = adaptive_padding_collate_fn
augm_func = get_augm_func(time_mask_param=40, freq_mask_param=16, crop_augm_max_cut_size=40)

MAX_LENGTH = 16
get_train_weights = None

# model
model_setting = [
    # t, c, n, s
    [1, 16, 1, 1],
    [2, 32, 2, 2],
    [2, 64, 6, 2],
    [2, 128, 6, 2],
]

model = ConvSelfAttentionMobileNet(model_setting,
                                   n_classes=4,
                                   last_channel=128)


def get_train_dataset(_df, ds_base_path):
    return MelEmotionsDataset(_df,
                              get_weights_func=get_train_weights,
                              augm_transform=augm_func,
                              base_path=ds_base_path)


def get_val_dataset(_df, ds_base_path):
    return MelEmotionsDataset(_df, base_path=ds_base_path)


def get_train_dataloader(train_ds):
    return DataLoader(train_ds, batch_size=batch_size, num_workers=1,
                      collate_fn=collate_fn,
                      sampler=LengthWeightedSampler(df=train_ds.df,
                                                    batch_size=batch_size,
                                                    min_length=0.3,
                                                    max_length=MAX_LENGTH,
                                                    length_delta=0.3,
                                                    decimals=1))


def get_val_dataloader(val_ds):
    return DataLoader(val_ds, batch_size=1, num_workers=4, shuffle=False)


train_dataset = get_train_dataset(load_jsonl_as_df(train_manifest_path),
                                  ds_base_path=train_manifest_path.parent)
val_dataset = get_val_dataset(load_jsonl_as_df(val_manifest_path),
                              ds_base_path=val_manifest_path.parent)

dataloaders = {'train': get_train_dataloader(train_ds=train_dataset),
               'validate': get_val_dataloader(val_ds=val_dataset)}

DUMP_BEST_CHECKPOINTS = True
DUMP_LAST_CHECKPOINTS = True
BEST_CHECKPOINTS_WARMUP = 5
